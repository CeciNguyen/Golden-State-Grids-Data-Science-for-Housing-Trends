{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfb77a3-79d3-439f-b110-3e2d421bcf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec20207-111f-4aca-800f-57cf479aad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "calihouse_data = pd.read_csv('california_housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d144978-e6df-4a4f-9c54-362589c3ac6c",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "First, let's check the shape and size of the data set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbb4cc2-4009-41b2-bd90-0ed381eaf958",
   "metadata": {},
   "outputs": [],
   "source": [
    "calihouse_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a72aabb-7001-4bba-b0b5-d76b18090759",
   "metadata": {},
   "outputs": [],
   "source": [
    "calihouse_data.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65176ce9-9ba8-49ca-9118-fc943af06c40",
   "metadata": {},
   "source": [
    "Wow! This is one extensive data set. Let's do a deeper dive and get some information about the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ca399c-34dd-42c0-81a0-ce0543ef6d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "calihouse_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffc187d-93e0-44a5-9a5b-9d1d20d39001",
   "metadata": {},
   "source": [
    "It seems like there is no null values, but we should check for duplicate rows!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2f7a12-51bd-41f9-86a2-19fcb6f873d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "calihouse_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0540e79c-6943-4580-99a7-d38a57f69937",
   "metadata": {},
   "source": [
    "YIPPEE! We do not have any duplicated values but let's double check if we need to do any data type conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50478c3-dfd7-4f8f-86c2-5c41ba1bbbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "calihouse_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1154ce-4176-4a54-8b29-d872f6804593",
   "metadata": {},
   "outputs": [],
   "source": [
    "calihouse_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2b214a-9645-4280-a050-57381b3f5cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Median IncomeColumn:\", calihouse_data['MedInc'].unique())\n",
    "print(\"House Age Column:\", calihouse_data['HouseAge'].unique())\n",
    "print(\"Average Rooms Column:\", calihouse_data['AveRooms'].unique())\n",
    "print(\"Average Bedrooms Column:\", calihouse_data['AveBedrms'].unique())\n",
    "print(\"Population Column:\", calihouse_data['Population'].unique())\n",
    "print(\"Average Occupancy Column:\", calihouse_data['AveOccup'].unique())\n",
    "print(\"Latitude Column:\", calihouse_data['Latitude'].unique())\n",
    "print(\"Longitude Column:\", calihouse_data['Longitude'].unique())\n",
    "print(\"Price Above Median Column:\", calihouse_data['price_above_median'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a561f-fcd6-4511-906b-9e3de3945eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Median Income Column:\", calihouse_data['MedInc'].nunique())\n",
    "print(\"House Age Column:\", calihouse_data['HouseAge'].nunique())\n",
    "print(\"Average Rooms Column:\", calihouse_data['AveRooms'].nunique())\n",
    "print(\"Average Bedrooms Column:\", calihouse_data['AveBedrms'].nunique())\n",
    "print(\"Population Column:\", calihouse_data['Population'].nunique())\n",
    "print(\"Average Occupancy Column:\", calihouse_data['AveOccup'].nunique())\n",
    "print(\"Latitude Column:\", calihouse_data['Latitude'].nunique())\n",
    "print(\"Longitude Column:\", calihouse_data['Longitude'].nunique())\n",
    "print(\"Price Above Median Column:\", calihouse_data['price_above_median'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43e08f6-2bdf-4d6d-9724-076da8e07823",
   "metadata": {},
   "source": [
    "It looks like there is not a need for any data type conversions! All the data types are in float64, except for `price_above_median` which is in int64, and the values reflect that! Let's try to find any anamolies in the data by running through some statistical tests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74321047-93a7-43f1-bd18-17bd5eca3fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Median Income Column Median:\", calihouse_data['MedInc'].median())\n",
    "print(\"House Age Column Median:\", calihouse_data['HouseAge'].median())\n",
    "print(\"Average Rooms Column Median:\", calihouse_data['AveRooms'].median())\n",
    "print(\"Average Bedrooms Column Median:\", calihouse_data['AveBedrms'].median())\n",
    "print(\"Population Column Median:\", calihouse_data['Population'].median())\n",
    "print(\"Average Occupancy Column Median:\", calihouse_data['AveOccup'].median())\n",
    "print(\"Longitude Latitude Column Median:\", calihouse_data['Longitude'].median())\n",
    "print(\"Latitude Column Median:\", calihouse_data['Latitude'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75e971b-6ced-4a5f-8d24-e162aef26d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Median Income Column mean:\", calihouse_data['MedInc'].mean())\n",
    "print(\"House Age Column mean:\", calihouse_data['HouseAge'].mean())\n",
    "print(\"Average Rooms Column mean:\", calihouse_data['AveRooms'].mean())\n",
    "print(\"Average Bedrooms Column mean:\", calihouse_data['AveBedrms'].mean())\n",
    "print(\"Population Column mean:\", calihouse_data['Population'].mean())\n",
    "print(\"Average Occupancy Column mean:\", calihouse_data['AveOccup'].mean())\n",
    "print(\"Longitude Latitude Column mean:\", calihouse_data['Longitude'].mean())\n",
    "print(\"Latitude Column mean:\", calihouse_data['Latitude'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49d8d92-27ce-4df9-b07d-8865395f6c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Median Income Column min:\", calihouse_data['MedInc'].min())\n",
    "print(\"House Age Column min:\", calihouse_data['HouseAge'].min())\n",
    "print(\"Average Rooms Column min:\", calihouse_data['AveRooms'].min())\n",
    "print(\"Average Bedrooms Column min:\", calihouse_data['AveBedrms'].min())\n",
    "print(\"Population Column min:\", calihouse_data['Population'].min())\n",
    "print(\"Average Occupancy Column min:\", calihouse_data['AveOccup'].min())\n",
    "print(\"Longitude Latitude Column min:\", calihouse_data['Longitude'].min())\n",
    "print(\"Latitude Column min:\", calihouse_data['Latitude'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85111d23-6232-4e42-bc44-eec84415e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Median Income Column max:\", calihouse_data['MedInc'].max())\n",
    "print(\"House Age Column max:\", calihouse_data['HouseAge'].max())\n",
    "print(\"Average Rooms Column max:\", calihouse_data['AveRooms'].max())\n",
    "print(\"Average Bedrooms Column max:\", calihouse_data['AveBedrms'].max())\n",
    "print(\"Population Column max:\", calihouse_data['Population'].max())\n",
    "print(\"Average Occupancy Column max:\", calihouse_data['AveOccup'].max())\n",
    "print(\"Longitude Latitude Column max:\", calihouse_data['Longitude'].max())\n",
    "print(\"Latitude Column max:\", calihouse_data['Latitude'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249576bc-94cd-41b6-ab2d-f28c820882ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Median Income Column standard deviation:\", calihouse_data['MedInc'].std())\n",
    "print(\"House Age Column standard deviation:\", calihouse_data['HouseAge'].std())\n",
    "print(\"Average Rooms Column standard deviation:\", calihouse_data['AveRooms'].std())\n",
    "print(\"Average Bedrooms Column standard deviation:\", calihouse_data['AveBedrms'].std())\n",
    "print(\"Population Column standard deviation:\", calihouse_data['Population'].std())\n",
    "print(\"Average Occupancy Column standard deviation:\", calihouse_data['AveOccup'].std())\n",
    "print(\"Longitude Latitude Column standard deviation:\", calihouse_data['Longitude'].std())\n",
    "print(\"Latitude Column standard deviation:\", calihouse_data['Latitude'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807fcf2c-b835-49d5-bad3-e30abfa82f74",
   "metadata": {},
   "source": [
    "Phew! Okay we did a lot of statistical methods on our data set but let's analyze what each column is telling us! \n",
    "\n",
    "1) Median Income (MedInc): The median and mean are close, suggesting a relatively normal distribution. However, the max value of 15.00 is quite high compared to the mean of 3.87.\n",
    "2) House Age (HouseAge): The oldest houses are 52 years old, and the youngest is 1 year old. The distribution seems reasonable.\n",
    "3) Average Rooms (AveRooms): The max value of 141.91 is an anomaly—this suggests an outlier where a block has an abnormally high average number of rooms.\n",
    "4) Average Bedrooms (AveBedrms): The max value of 34.07 bedrooms per unit is extremely high and likely an anomaly.\n",
    "5) Population: The max value 35,682 suggests a highly populated block, which is significantly above the mean (1,425).\n",
    "6) Average Occupancy (AveOccup): The max of 1,243.33 seems like an outlier since the mean is only 3.07. This suggests that some data points may have incorrect values.\n",
    "7) Longitude & Latitude: These values align with California’s geographical bounds.\n",
    "\n",
    "One thing that we didn't analyze yet is our `price_above_median` column. This is because this is the only dependent variable within the whole dataset. So, let's do some analysis on this variable to better understand what is happening wiht this column!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a14072-4b13-4702-92cf-8707d9ade4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calihouse_data['price_above_median'].value_counts()) #this is to check if the data is balanced between houses priced above and below the median\n",
    "print(calihouse_data['price_above_median'].value_counts(normalize=True)) #this gives us the percentage of houses priced above and below the median\n",
    "print(calihouse_data.groupby('price_above_median').mean()) #this will tell me the average median income, house age, number of rooms etc, for each group \n",
    "print(calihouse_data.corr()['price_above_median'].sort_values(ascending=False)) #this will tell which factors most strongly influence home prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f8ed92-45de-411c-83cc-b07567820595",
   "metadata": {},
   "source": [
    "Okay, so what does this tell us?\n",
    "\n",
    "1) The dataset is perfectly balanced! 50% of the houses are above the median price and 50% of the houses are below the median price. This means we can take a breath of relief because we do not have to worry about class imbalance. This also means that this dataset is great for predictive modeling!\n",
    "\n",
    "2) Some Key differences between the below and above median price houses:\n",
    "    - Median Income (MedInc): Income has a strong positive relationship with house price. Houses in higher-income areas are much more likely to be priced above the median.\n",
    "    - House Age (HouseAge): Slightly older homes tend to be priced higher, but the difference isn’t large.\n",
    "    - Average Rooms (AveRooms): Homes with more rooms tend to be above the median price. This makes sense because larger houses are usually more expensive.\n",
    "    - Average Bedrooms (AveBedrms): Slightly fewer bedrooms in more expensive homes. This might indicate that larger houses with fewer, more spacious rooms are more valuable.\n",
    "    - Population (Population): Population size does not seem to be a strong factor in determining house price.\n",
    "    - Average Occupancy (AveOccup): More expensive homes tend to have fewer occupants per household, possibly indicating larger houses with more space per person.\n",
    "    - Latitude (Latitude): Higher-priced houses tend to be slightly further south, suggesting that more expensive homes may be located in urban or coastal regions.\n",
    "    - Longitude (Longitude): Expensive homes are slightly further west, potentially closer to coastal areas.\n",
    "  \n",
    "3) Some potential anomalies and key insights are:\n",
    "    - Average bedrooms being lower for higher-priced houses is unexpected but might make sense if expensive homes have more open space per room.\n",
    "    - Population is nearly identical for both price categories, meaning it likely has little impact on house prices.\n",
    "    - Latitude and Longitude differences suggest a geographic influence on pricing, possibly due to proximity to the coast or urban centers.\n",
    "  \n",
    "4) Let's interpret the correlation values:\n",
    "    - Strongest Positive Correlation:\n",
    "        - MedInc (High correlation): Higher median income strongly predicts a house being above the median price.\n",
    "        - Latitude (Moderate correlation): Suggests homes further north (around the Bay Area and coastal cities) tend to be more expensive.\n",
    "    - Strongest Negative Correlation:\n",
    "        - AveOccup (Negative correlation): Indicates higher occupancy per home is associated with lower-priced houses, possibly reflecting more crowded living conditions in lower-income areas.\n",
    "        - Longitude (Negative correlation): Suggests homes further west (closer to Los Angeles and San Francisco) are generally higher-priced. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70db125-58a8-47ce-a361-355e052acc12",
   "metadata": {},
   "source": [
    "# Univariate Analysis\n",
    "Now that we have introduced ourselves to the dataset a bit, let's visualize the dataset to get a better understanding of what we are dealing with here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4ed85b-80ad-4c16-897a-57548c3a7042",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.subplot(4, 2, 1)\n",
    "sns.histplot(calihouse_data['MedInc'], bins=30, kde=True, color=\"red\")\n",
    "plt.title('Distribution of MedInc')\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "sns.histplot(calihouse_data['HouseAge'], bins=30, kde=True, color=\"orange\")\n",
    "plt.title('Distribution of HouseAge')\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "sns.histplot(calihouse_data['AveRooms'], bins=30, kde=True, color=\"gold\")\n",
    "plt.title('Distribution of AveRooms')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "sns.histplot(calihouse_data['AveBedrms'], bins=30, kde=True, color=\"yellowgreen\")\n",
    "plt.title('Distribution of AveBedrms')\n",
    "\n",
    "plt.subplot(4, 2, 5)\n",
    "sns.histplot(calihouse_data['Population'], bins=30, kde=True, color=\"blue\")\n",
    "plt.title('Distribution of Population')\n",
    "\n",
    "plt.subplot(4, 2, 6)\n",
    "sns.histplot(calihouse_data['AveOccup'], bins=30, kde=True, color=\"indigo\")\n",
    "plt.title('Distribution of AveOccup')\n",
    "\n",
    "plt.subplot(4, 2, 7)\n",
    "sns.histplot(calihouse_data['Latitude'], bins=30, kde=True, color=\"orchid\")\n",
    "plt.title('Distribution of Latitude')\n",
    "\n",
    "plt.subplot(4, 2, 8)\n",
    "sns.histplot(calihouse_data['Longitude'], bins=30, kde=True, color=\"hotpink\")\n",
    "plt.title('Distribution of Longitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7d4f96-79fc-4e51-ab28-4d2f1fb529a4",
   "metadata": {},
   "source": [
    "This is quite interesting!\n",
    "\n",
    "The distributions of `MedInc`, `AveRooms`, `AveBedrms`, `Population`, and `AveOccup` are all right skewed. Let's look into each of these graphs:\n",
    "1) MedInc (Median Income): Right-skewed distribution, meaning most households have lower incomes, with a few having significantly higher values.\n",
    "2) AveRooms & AveBedrms: Right-skewed, with a majority of houses having fewer rooms and bedrooms.\n",
    "3) Population: Strong right-skew, indicating that most block groups have lower populations, with a few significantly larger ones.\n",
    "4) AveOccup (Average Occupancy): Highly skewed, suggesting that most households have lower occupancy rates, with extreme values present.\n",
    "   \n",
    "The rest of the graphs look fairly uniform! But, let's look into them:\n",
    "\n",
    "5) HouseAge: Fairly uniform distribution, but some peaks around newer housing developments.\n",
    "6) Latitude & Longitude: These show a relatively uniform spread, reflecting the geographical distribution of houses across California."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836d75e2-f291-4a70-a8c2-7e0c59d3a199",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.subplot(4, 2, 1)\n",
    "sns.boxplot(y=calihouse_data['MedInc'], color=\"red\")\n",
    "plt.title('Box Plot of MedInc')\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "sns.boxplot(y=calihouse_data['HouseAge'], color=\"orange\")\n",
    "plt.title('Box Plot of HouseAge')\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "sns.boxplot(y=calihouse_data['AveRooms'], color=\"gold\")\n",
    "plt.title('Box Plot of AveRooms')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "sns.boxplot(y=calihouse_data['AveBedrms'], color=\"yellowgreen\")\n",
    "plt.title('Box Plot of AveBedrms')\n",
    "\n",
    "plt.subplot(4, 2, 5)\n",
    "sns.boxplot(y=calihouse_data['Population'], color=\"blue\")\n",
    "plt.title('Box Plot of Population')\n",
    "\n",
    "plt.subplot(4, 2, 6)\n",
    "sns.boxplot(y=calihouse_data['AveOccup'], color=\"indigo\")\n",
    "plt.title('Box Plot of AveOccup')\n",
    "\n",
    "plt.subplot(4, 2, 7)\n",
    "sns.boxplot(y=calihouse_data['Latitude'], color=\"orchid\")\n",
    "plt.title('Box Plot of Latitude')\n",
    "\n",
    "plt.subplot(4, 2, 8)\n",
    "sns.boxplot(y=calihouse_data['Longitude'], color=\"hotpink\")\n",
    "plt.title('Box Plot of Longitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eba8bc3-10a1-4e68-a6df-caefa43d9f23",
   "metadata": {},
   "source": [
    "Here are some interesting insights and correlations I found with the box plots:\n",
    "1) MedInc & HouseAge: Outliers present in high-income households and very old houses.\n",
    "2) Population & AveOccup: These show extreme outliers, indicating some block groups have exceptionally high population density.\n",
    "3) AveRooms & AveBedrms: Outliers suggest that some houses have an unusually high number of rooms and bedrooms.\n",
    "4) Latitude & Longitude: Most houses are concentrated in Central and Southern California."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9352f1b-1911-475e-b4b3-9854d8d945e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='price_above_median', y='MedInc', data=calihouse_data,  color=\"lavender\")\n",
    "plt.title(\"Median Income vs. Price Category\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c737810-c5aa-49f4-a889-58f3a73b925c",
   "metadata": {},
   "source": [
    "We can see from the plot above: \n",
    "1) Houses priced above the median (price_above_median = 1) tend to be located in areas with higher median incomes, as the distribution of median income is shifted upward for higher-priced homes. This suggests a strong positive correlation between income levels and home prices—wealthier areas generally have more expensive homes.\n",
    "2) On the other hand, the interquartile range (IQR) for lower-priced houses (price_above_median = 0) is wider, indicating greater variation in household income within these neighborhoods. This could suggest that lower-priced housing is spread across a broader spectrum of income groups, encompassing both low-income and some middle-income areas.\n",
    "3) There may be outliers in the higher price category, which could represent exceptionally wealthy neighborhoods where the median income is significantly above the typical range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5350f63d-06de-402a-8e53-bc1a97d28e73",
   "metadata": {},
   "source": [
    "# Classification Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fe3471-e1d9-41c6-93ca-6a55a20ad81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "X = calihouse_data.drop(columns=['price_above_median'])  \n",
    "y = calihouse_data['price_above_median']  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print(\"Class distribution in original dataset:\\n\", y.value_counts(normalize=True))\n",
    "print(\"Class distribution in training set:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"Class distribution in test set:\\n\", y_test.value_counts(normalize=True))\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10792f7-9397-495f-afe1-6b1e5e33dc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn_params = {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance']}\n",
    "grid_knn = GridSearchCV(knn, knn_params, cv=5, scoring='accuracy')\n",
    "grid_knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "knn_best = grid_knn.best_estimator_\n",
    "y_pred_knn = knn_best.predict(X_test_scaled)\n",
    "print(\"KNN Classification Report:\\n\", classification_report(y_test, y_pred_knn))\n",
    "print(\"KNN Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(\"KNN AUC-ROC:\", roc_auc_score(y_test, knn_best.predict_proba(X_test_scaled)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f22936a-8a4d-44a1-b8af-c91a408f0536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision tree\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  \n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__max_depth': [5, 10, 15, 20, None],\n",
    "    'classifier__min_samples_split': [2, 5, 10, 20],\n",
    "    'classifier__min_samples_leaf': [1, 2, 5, 10],\n",
    "    'classifier__max_features': ['sqrt', 'log2', None],\n",
    "    'classifier__criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f63409a-77b0-4883-8002-67de5772c329",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest\n",
    "pipeline_rf = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Standardize the data\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_rf = {\n",
    "    'classifier__n_estimators': [50, 100, 200],  # Number of trees\n",
    "    'classifier__max_depth': [5, 10, 20, None],  # Tree depth\n",
    "    'classifier__min_samples_split': [2, 5, 10],  # Min samples required to split\n",
    "    'classifier__min_samples_leaf': [1, 2, 5],  # Min samples at leaf\n",
    "    'classifier__max_features': ['sqrt', 'log2', None],  # Feature selection strategy\n",
    "    'classifier__criterion': ['gini', 'entropy']  # Splitting criterion\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "rf_best = grid_rf.best_estimator_\n",
    "y_pred_rf = rf_best.predict(X_test)\n",
    "\n",
    "print(\"Best Random Forest Hyperparameters:\", grid_rf.best_params_)\n",
    "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Random Forest AUC-ROC:\", roc_auc_score(y_test, rf_best.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d08970-f031-447d-8f32-fc249eba449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adaboost\n",
    "pipeline_ab = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Standardize the data\n",
    "    ('classifier', AdaBoostClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_ab = {\n",
    "    'classifier__n_estimators': [50, 100, 200, 500],  # Number of weak learners\n",
    "    'classifier__learning_rate': [0.001, 0.01, 0.1, 1],  # Learning rate\n",
    "    'classifier__algorithm': ['SAMME', 'SAMME.R']  # Algorithm type\n",
    "}\n",
    "\n",
    "grid_ab = GridSearchCV(pipeline_ab, param_grid_ab, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_ab.fit(X_train, y_train)\n",
    "ab_best = grid_ab.best_estimator_\n",
    "y_pred_ab = ab_best.predict(X_test)\n",
    "\n",
    "print(\"Best AdaBoost Hyperparameters:\", grid_ab.best_params_)\n",
    "print(\"AdaBoost Classification Report:\\n\", classification_report(y_test, y_pred_ab))\n",
    "print(\"AdaBoost Accuracy:\", accuracy_score(y_test, y_pred_ab))\n",
    "print(\"AdaBoost AUC-ROC:\", roc_auc_score(y_test, ab_best.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120a5fa1-521a-4e8b-a1da-272df4ac4095",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'KNN': (knn_best, X_test_scaled),  #uses scaled data\n",
    "    'Decision Tree': (dt_best, X_test),  #uses unscaled data\n",
    "    'Random Forest': (rf_best, X_test),  #uses unscaled data\n",
    "    'AdaBoost': (ab_best, X_test)  #uses unscaled data\n",
    "}\n",
    "\n",
    "for name, (model, X_data) in models.items():\n",
    "    print(f\"{name} Accuracy: {accuracy_score(y_test, model.predict(X_data)):.4f}\")\n",
    "    print(f\"{name} AUC-ROC: {roc_auc_score(y_test, model.predict_proba(X_data)[:, 1]):.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0890d3eb-636d-49b3-b657-3cd5c8e900d5",
   "metadata": {},
   "source": [
    "WOW! These are some impressive results!! So, we know from project 1 that when we did not standardize the dataset then KNN would not perform well. After we scaled the data we can clearly see that the model did a lot better. After testing the scaled data on the KNN model I also tried it on the decision tree, random forest, and adaboost models to see if there was going to be a major difference. I found that there was not a big difference in the accuracy or the AUC-ROC. I am guessing this might be because these models are not scale sensitive.\n",
    "\n",
    "Just for funsies, let's see what would happen if we used ensemble learning or stacking. We will train multiple base models (KNN, decision tree, random forest, and adaboost) then use their prediction as an input for a meta model using logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec127ac1-d13b-45a6-956a-359e023a62de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4d45bc-1b69-4473-b187-3e22693798d9",
   "metadata": {},
   "source": [
    "Hmmm this is quite interesting! We computed a confusion matrix for both unscaled and scaled models. The results of the different classifiers provide valuable insights into the impact of scaling on their performance. For KNN, scaling had a significant positive effect. Without scaling, the confusion matrix showed weaker classification performance with more misclassifications, as KNN relies on distance calculations that can be dominated by features with larger scales. However, after standardization, the confusion matrix became more balanced, improving the model's ability to correctly classify instances. \n",
    "\n",
    "The decision tree classifier model, however, was unaffected by scaling. Since decision trees split features independently and do not rely on distance-based calculations, the confusion matrices remained nearly identical before and after scaling. Similarly, the random forest Classifier, like Decision Trees, showed no sensitivity to feature scaling, and the confusion matrices were almost identical. However, random forest's strong performance, with fewer misclassifications compared to decision trees, suggests it generalizes better by reducing overfitting. AdaBoost classifier also showed no significant change with scaling, and while it performed well, it might not have been as strong as Random Forest due to its sensitivity to noisy data and weaker base estimators. \n",
    "\n",
    "Overall, scaling significantly impacted KNN, but had little effect on decision trees, random forest, or adaboost. Random forest emerged as a top-performing model regardless of scaling, making it a strong choice for this dataset. For computational efficiency, decision trees may be a good option as they are simpler while still maintaining decent accuracy. When misclassification penalties are high, model selection should prioritize precision and recall over accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
